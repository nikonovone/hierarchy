# **Тестовое задание на отборочный этап стажировки в Kazan Express 2023**

## **Описание задачи**
В маркетплейс каждый день поступает множество новых товаров и каждый из них необходимо отнести в определенную категорию в нашем дереве категорий. На это тратится много сил и времени, поэтому мы хотим научиться предсказывать категорию на основе названий и параметров товаров.

---
## Формат данных
<details>
<summary>Описание данных</summary>

По [**ссылке на google drive**](https://drive.google.com/drive/folders/194JOoKDZCkmpBglf7Fs7hlzk5xXJSYgI?usp=sharing) лежат три файла:

**categories_tree.csv** - файл с деревом категорий на маркетплейсе. У каждой категории есть id, заголовок и parent_id, по которому можно восстановить полный путь категории.

Допустим у категории `2642` заголовок "Мелкие инструменты", а путь в дереве категорий - `10016->10072->10690->2642`. Если заменить id категорий в этом пути на заголовки, то получим следующее дерево:

- Строительство и ремонт
    - Ручной инструмент и оснастка
        - Столярно-слесарные инструменты
            - Мелкие инструменты

**train.parquet** - файл с товарами на маркетплейсе.
У каждого товара есть:

- *id* - идентификатор товара
- *title - заголовок*
- *short_description - краткое описание*
- *name_value_characteristics - название:значение* характеристики товара, может быть несколько для одного товара и для одной характеристик. Пример: `name1: value1 | value2 | valueN_1 / name2: value1 | value2 | valueN_2 / nameK: value1 | value2 | valueN_K`
- *rating - средний рейтинг товара*
- *feedback_quantity - количество отзывов по товару*
- *category_id - категория товара(таргет)*

**test.parquet** - файл идентичный **train.parquet**, но без реального *category_id*, именно его вам и предстоит предсказать.

</details>

---
## Особенности:
* большой дисбаланс: есть множество пустых категорий, категорий, в которые попадают всего 2 товара, есть категории с тысячами товаров.
* тексты простые, не наполнены смыслом, раскрывающимся из контекста, это близко к набору ключевых слов, значит, простые модели на основе "мешка слов" должны работать не хуже сложных.

## Описание решения:
Так как было выяснено, что fit_predict **fastext** дает скор 0.8-0.9 с флуктуациями, было принято решение попробовать сделать решение с учетом картинок. изначально была идея лоабвит эмбеддинг полученный простой сверткой **EfficienNet B3 Pruned** к эмбеддингу от текста и обучить на это классфикатор в виде Multilayer Perceptron, однако даный подход не дал результатов. После было принято решение попробовать реализовать решение в новой для себя области - **Multymodal Neural Network**

Моделью для такого эксперимента была выбрана [**Google’s CoCa Model**](https://arxiv.org/abs/2205.01917), так как она свежая, для нее есть реализация на torch, она является State-of-the-art решением во многих областях.
На Рис. 1 изображена схема архитектуры модели иее сравнение с другими решениями.

<p align="center">
  <img src="https://vaclavkosar.com/images/coca-pretraining.png" height = 300 />
  <img src="https://vaclavkosar.com/images/coca-results.png" height = 300 />
  <p align="center">
  <em>Рис.1 Схематическая архитектура CoCa модели и сравнение с другим моделями</em>
  </p>
</p>

Так как на вход помимо картинки модель получает закодированные токены текста.
Былы использована библиотека [**Natasha**](https://github.com/natasha/natasha), с помощью словаря на 500 000 слов из модуля **Navec**, текст был лемматизирован и разбит на закодированные токены (вектор длинной 300).

Далее, используя [**Pytorch Lightning**](https://lightning.ai) для тренировки и [**Tensorboard**](https://www.tensorflow.org/tensorboard) для логирования планировалось обучить CoCa модель выдавать схожие эмбеддинги, и далее обучить простейший Multilayer Perceptron в качестве классификатора.

В ходе обучения возникла главная проблема - нехватка вычислительных мощностей, CoCa модель крайне жирная. Одна эпоха занимала 9+ часов, размер батча ограничивался 2-3 картинками. В связи с небольшим количеством времени выделенное под данное задание, обучить модель удалось буквально на 2 эпохи, что сказалось на конечном результате.

## Описание файлов

**coca_train.ipynb** - обучение модели CoCa

**inference.ipynb** - предсказания

## Выводы
Модель показала плохой скор относительно базового решение с **fasttext**, повлияла на это недообученность, или какие-либо ошибки в логике обучения, предстоит выяснить :)