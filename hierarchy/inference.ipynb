{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><b>Импорт библиотек</b></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from navec import Navec\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from utils.dataset_mlp import DataModule\n",
    "from utils.model_coca import ClassifierCOCA\n",
    "from utils.model_mlp import ClassifierMLP\n",
    "from utils.utils import (cleanhtml, lemmatize, normalization_df, predict,\n",
    "                         train_model_mvp, transform_tokens)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><b>Установка путей и констант</b></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path('data')\n",
    "LOG_PATH = Path('logs')\n",
    "MODELS_PATH = Path('models')\n",
    "CHECKPOINT_PATH = Path('checkpoints')\n",
    "IMAGES_PATH = DATA_PATH / 'images'\n",
    "\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "LOG_PATH.mkdir(parents=True, exist_ok=True)\n",
    "CHECKPOINT_PATH.mkdir(parents=True, exist_ok=True)\n",
    "TEXT_MODEL = MODELS_PATH / 'navec_hudlit_v1_12B_500K_300d_100q.tar'  # 471 MB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры обучения:\n",
    "# случайное зерно\n",
    "SEED = 13\n",
    "# номер видеокарты\n",
    "GPU_ID = 1\n",
    "# размер валидационной выборки\n",
    "VAL_SIZE = 0.15\n",
    "# количество эпох обучения\n",
    "NUM_EPOCHS = 25\n",
    "# размер батча\n",
    "BATCH_SIZE = 256\n",
    "# скорость обучения\n",
    "LEARNING_RATE = 1e-3\n",
    "# число задействованных ядер\n",
    "NUM_WORKERS = 12\n",
    "# количество классов\n",
    "NUM_CLASSES = 874\n",
    "# размер изображения для ресайза\n",
    "IMAGE_SIZE = 256\n",
    "# длина эмбеддинга изображения\n",
    "IMAGE_EMB_LEN = 300\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><b>Чтение данных</b></center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "navec = Navec.load(TEXT_MODEL)\n",
    "train_df = pd.read_parquet(DATA_PATH / 'train.parquet', engine='fastparquet')\n",
    "train_df['title'] = train_df.apply(lambda x: lemmatize(\n",
    "    cleanhtml(x.text_fields)['title'], navec), axis=1)\n",
    "train_df['category_id'] = train_df['category_id'].astype('category').cat.codes\n",
    "train_df.head(3)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><b>Разбиение на тренировачную и тестовую выборки</b></center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(train_df, test_size=0.25, random_state=SEED)\n",
    "\n",
    "train = train[train['title'].astype(str) != '[]']\n",
    "test = test[test['title'].astype(str) != '[]']\n",
    "\n",
    "train['title'] = train.title.apply(transform_tokens)\n",
    "test['title'] = test.title.apply(transform_tokens)\n",
    "\n",
    "train = train[['product_id', 'title', 'category_id']]\n",
    "test = test[['product_id', 'title', 'category_id']]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><b>Загрузка модели</b></center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_hparams = {'batch_size': BATCH_SIZE,\n",
    "                 'len_image_emb': IMAGE_EMB_LEN,\n",
    "                 'num_classes': NUM_CLASSES,\n",
    "                 'image_size': IMAGE_SIZE\n",
    "                 }\n",
    "optimizer_params = {'name': 'RAdam',\n",
    "                    'lr': LEARNING_RATE}\n",
    "model_coca = ClassifierCOCA(model_hparams=model_hparams,\n",
    "                       optimizer_params=optimizer_params)\n",
    "checkpoint = torch.load(\n",
    "    'checkpoints/coca_RAdam/epoch=1-val_loss=5.23014.ckpt')\n",
    "model_coca.load_state_dict(checkpoint['state_dict'])\n",
    "model_coca.to(device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><b>Получение предсказаний</b></center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_path = IMAGES_PATH / 'train'\n",
    "image_embd_train, text_embd_train = predict(train, model_coca, images_path, device)\n",
    "image_embd_test, text_embd_test = predict(test, model_coca, images_path, device)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><b>Нормализация и разделение данных</b></center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_emb = normalization_df(image_embd_train,text_embd_train)\n",
    "test_emb = normalization_df(image_embd_test,text_embd_test)\n",
    "y_train = train['category_id'].values\n",
    "y_test = test['category_id'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_values = np.concatenate([train_emb, y_train[...,np.newaxis]], axis = 1)\n",
    "test_values = np.concatenate([test_emb, y_test[...,np.newaxis]], axis = 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><b>Обучение классификатора</b></center></h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Убедимся, что все операции детерминированы на графическом процессоре\n",
    "# (если он используется) для воспроизводимости.\n",
    "torch.backends.cudnn.determinstic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# создание объекта логгирования(тензорборд)\n",
    "name = 'mvp'\n",
    "tensor_logger = TensorBoardLogger(LOG_PATH, name=name)\n",
    "# создание модуля данных\n",
    "datamodule = DataModule(train_values,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        num_workers=NUM_WORKERS,\n",
    "                        val_size=VAL_SIZE,\n",
    "                        seed=SEED)\n",
    "model_hparams = {'batch_size': BATCH_SIZE,\n",
    "                 'len_image_emb': 300,\n",
    "                 'num_classes': NUM_CLASSES\n",
    "                 }\n",
    "optimizer_params = {'name': 'AdamW',\n",
    "                    'lr': LEARNING_RATE}\n",
    "trainer = train_model_mvp(\n",
    "    model_hparams=model_hparams,\n",
    "    optimizer_params=optimizer_params,\n",
    "    ckpt_path=None,\n",
    "    logger=tensor_logger,\n",
    "    scheduler=None,\n",
    "    checkpoint_path=CHECKPOINT_PATH / f'{name}_{optimizer_params[\"name\"]}',\n",
    "    device=device,\n",
    "    gpu_id=[0],\n",
    "    num_epochs=NUM_EPOCHS,\n",
    "    data_module=datamodule,\n",
    "    seed=SEED,\n",
    "    unfreeze_epoch=None\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><b>Расчет метрик</b></center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "model_hparams = {'batch_size': BATCH_SIZE,\n",
    "                 'len_image_emb': 300,\n",
    "                 'num_classes': NUM_CLASSES\n",
    "                 }\n",
    "optimizer_params = {'name': 'RAdam',\n",
    "                    'lr': LEARNING_RATE}\n",
    "model = ClassifierMLP(model_hparams=model_hparams,\n",
    "                      optimizer_params=optimizer_params)\n",
    "checkpoint = torch.load(\n",
    "    '/4tb/nikonov/hierarchy/hierarchy/checkpoints/mvp_AdamW/epoch=7-val_loss=1.43775.ckpt')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model(torch.from_numpy(test_values[:,:-1]))\n",
    "_, predicted = torch.max(preds.data, 1)\n",
    "f1_score(test_values[:,-1:], predicted, average='macro')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center><b>Тестовый инференс</b></center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_parquet(DATA_PATH / 'test.parquet', engine='fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 16860/16860 [03:54<00:00, 71.92it/s]\n"
     ]
    }
   ],
   "source": [
    "test_data['title'] = test_data.apply(lambda x: lemmatize(\n",
    "    cleanhtml(x.text_fields)['title'], navec), axis=1)\n",
    "test_data = test_data[['product_id', 'title']]\n",
    "images_path = IMAGES_PATH / 'test'\n",
    "image_test, text_test = predict(test_data, model_coca, images_path, device)\n",
    "test_emb = normalization_df(image_test,text_test)\n",
    "preds = model(torch.from_numpy(test_emb))\n",
    "_, predicted = torch.max(preds.data, 1)\n",
    "\n",
    "result = pd.DataFrame({'id': test_data.product_id, 'predicted_category_id':predicted})\n",
    "result.to_parquet('result.parquet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
